{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1m0c4zu8Qz3xUjJp_64s2MHWebcd9CmH-",
      "authorship_tag": "ABX9TyO+r7AepSGvHj3ai0GnHcV/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fsndzomga/Deep-Learning-With-Python/blob/main/The_next_word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ttbbzaxPKYSB"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_text(text_file_path):\n",
        "    # Loading my text file\n",
        "    text = open(text_file_path, \"r\").read().lower()\n",
        "\n",
        "    # Remove numbers using isdigit()\n",
        "    text = ''.join([c for c in text if not c.isdigit()])\n",
        "\n",
        "    # Remove punctuation using str.translate() and string.punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "    # Replace multiple spaces with single space\n",
        "    text = re.sub(' +', ' ', text)\n",
        "\n",
        "    # Replace line breaks with single space\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "R59VdH2bKhq0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoding(text):\n",
        "    # Generate the list of unique words in my text\n",
        "    unique_words = set(text.split(\" \"))\n",
        "\n",
        "    # Get the number of elements in the set\n",
        "    num_elements = len(unique_words)\n",
        "\n",
        "    #load an encoding map that was previously created\n",
        "    with open(\"/content/drive/MyDrive/Machine Learning Files/encoding.json\", \"r\") as file:\n",
        "      json_data = file.read()\n",
        "      text_encoding = json.loads(json_data)\n",
        "\n",
        "\n",
        "    # use the text encoding to map the original corpus\n",
        "    encoded_text = [text_encoding[word] for word in text.split(\" \")]\n",
        "\n",
        "    return encoded_text"
      ],
      "metadata": {
        "id": "mcdwvTsTKt-P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data, timesteps):\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(timesteps, len(data)):\n",
        "    X.append(data[i-timesteps:i])\n",
        "    y.append(data[i])\n",
        "  X, y = np.array(X), np.array(y)\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "IkZXl59sLS1o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = preprocessing_text(\"/content/drive/MyDrive/Machine Learning Files/bible.txt\")\n",
        "\n",
        "encoded_text = encoding(text)\n"
      ],
      "metadata": {
        "id": "5p4KCb2bKwld"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps = 5\n",
        "X, y = prepare_data(encoded_text, timesteps)\n",
        "\n",
        "# split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8)\n",
        "\n",
        "\n",
        "# create and compile the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(500, activation='relu', return_sequences=True, input_shape=(timesteps, 1)))\n",
        "model.add(LSTM(500, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse',  metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "\n",
        "# fit the model to the training data\n",
        "model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
        "\n",
        "# evaluate the model on the testing data\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print('Test loss:', loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66JPqbQMMLC9",
        "outputId": "059fdf1a-d760-4864-dfb7-ef44924f4ff4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4203/4203 [==============================] - 131s 30ms/step - loss: 14816313.0000 - mean_absolute_error: 3202.3647 - val_loss: 14601699.0000 - val_mean_absolute_error: 3148.7385\n",
            "Epoch 2/10\n",
            "4203/4203 [==============================] - 128s 30ms/step - loss: 14495164.0000 - mean_absolute_error: 3185.6157 - val_loss: 14737823.0000 - val_mean_absolute_error: 3140.0911\n",
            "Epoch 3/10\n",
            "4203/4203 [==============================] - 126s 30ms/step - loss: 14541526.0000 - mean_absolute_error: 3188.3857 - val_loss: 14880279.0000 - val_mean_absolute_error: 3138.0173\n",
            "Epoch 4/10\n",
            "4203/4203 [==============================] - 127s 30ms/step - loss: 14498281.0000 - mean_absolute_error: 3185.1240 - val_loss: 15241041.0000 - val_mean_absolute_error: 3139.1531\n",
            "Epoch 5/10\n",
            "4203/4203 [==============================] - 126s 30ms/step - loss: 14508635.0000 - mean_absolute_error: 3186.0076 - val_loss: 14447760.0000 - val_mean_absolute_error: 3200.1602\n",
            "Epoch 6/10\n",
            "4203/4203 [==============================] - 127s 30ms/step - loss: 14454124.0000 - mean_absolute_error: 3182.9541 - val_loss: 14466247.0000 - val_mean_absolute_error: 3208.9475\n",
            "Epoch 7/10\n",
            "4203/4203 [==============================] - 129s 31ms/step - loss: 14431066.0000 - mean_absolute_error: 3181.3123 - val_loss: 14609588.0000 - val_mean_absolute_error: 3247.7415\n",
            "Epoch 8/10\n",
            "4203/4203 [==============================] - 125s 30ms/step - loss: 14407240.0000 - mean_absolute_error: 3180.2334 - val_loss: 14399396.0000 - val_mean_absolute_error: 3190.2866\n",
            "Epoch 9/10\n",
            "4203/4203 [==============================] - 132s 31ms/step - loss: 14391693.0000 - mean_absolute_error: 3178.3440 - val_loss: 14370531.0000 - val_mean_absolute_error: 3177.7974\n",
            "Epoch 10/10\n",
            "4203/4203 [==============================] - 131s 31ms/step - loss: 14362690.0000 - mean_absolute_error: 3175.1414 - val_loss: 14346023.0000 - val_mean_absolute_error: 3172.5374\n",
            "21015/21015 [==============================] - 99s 5ms/step - loss: 14335448.0000 - mean_absolute_error: 3174.4602\n",
            "Test loss: [14335448.0, 3174.460205078125]\n"
          ]
        }
      ]
    }
  ]
}